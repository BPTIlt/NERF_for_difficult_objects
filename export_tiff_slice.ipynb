{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://gist.github.com/kwea123/77ed1640f9bc9550136dc13a6a419e88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from models.nerf import Embedding, NeRF\n",
    "from utils import load_ckpt\n",
    "\n",
    "import tifffile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk = 1024 * 32\n",
    "img_wh = (3072, 2304)  # full resolution of the input images\n",
    "\n",
    "# ### Tune these parameters until the whole object lies tightly in range with little noise ###\n",
    "N = 1024 # controls the resolution, set this number small here because we're only finding\n",
    "        # good ranges here, not yet for mesh reconstruction; we can set this number high\n",
    "        # when it comes to final reconstruction.\n",
    "def get_coords(x):\n",
    "    cube_size = 4.0\n",
    "    return x - cube_size / 2, x + cube_size / 2\n",
    "\n",
    "xmin, xmax = get_coords(0) # left/right range\n",
    "ymin, ymax = get_coords(0) # forward/backward range\n",
    "zmin, zmax = get_coords(-4.5) # up/down range\n",
    "## Attention! the ranges MUST have the same length!\n",
    "############################################################################################\n",
    "\n",
    "scene_name = \"deer_v6_debug_script_picked_blurry\"\n",
    "EPOCH = 29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENTS = Path(\"../data/llff/\")\n",
    "CKPTS = Path(\"ckpts\")\n",
    "RESULTS = Path(\"results/llff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = EXPERIMENTS / f\"{scene_name}\"  # the folder containing data\n",
    "root_dir.mkdir(exist_ok=True)\n",
    "\n",
    "ckpt_path = CKPTS / f\"{scene_name}\" / f\"epoch={EPOCH}.ckpt\" # the model path\n",
    "\n",
    "embedding_xyz = Embedding(3, 10)\n",
    "embedding_dir = Embedding(3, 4)\n",
    "\n",
    "nerf_fine = NeRF()\n",
    "load_ckpt(nerf_fine, ckpt_path, model_name='nerf_fine')\n",
    "nerf_fine.cuda().eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/llff/deer_v6_debug_script_picked_blurry/tiff/deer_v6_debug_script_picked_blurry_volume_N=1024.tiff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "x = np.linspace(xmin, xmax, N)\n",
    "y = np.linspace(ymin, ymax, N)\n",
    "\n",
    "(RESULTS / f\"{scene_name}\" / \"tiff\").mkdir(exist_ok=True) # Create dir if needed\n",
    "volume_output_file = RESULTS / f\"{scene_name}\" / \"tiff\" / f\"{scene_name}_volume_N={N}.tiff\"\n",
    "print(str(volume_output_file))\n",
    "if volume_output_file.exists():\n",
    "    volume_output_file.unlink()\n",
    "\n",
    "for z in tqdm(np.linspace(zmin, zmax, N), total=N, leave=False):\n",
    "    xy_ = torch.FloatTensor(np.stack(np.meshgrid(x, y), -1).reshape(-1, 2)).cuda()\n",
    "    xyz_ = torch.cat((xy_, torch.full((xy_.shape[0], 1), z).cuda()), dim=1).cuda()\n",
    "\n",
    "    dir_ = torch.zeros_like(xyz_).cuda()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        B = xyz_.shape[0]\n",
    "        out_chunks = []\n",
    "        for i in range(0, B, chunk):\n",
    "            xyz_embedded = embedding_xyz(xyz_[i:i+chunk]) # (N, embed_xyz_channels)\n",
    "            dir_embedded = embedding_dir(dir_[i:i+chunk]) # (N, embed_dir_channels)\n",
    "            xyzdir_embedded = torch.cat([xyz_embedded, dir_embedded], 1)\n",
    "            out_chunks += [nerf_fine(xyzdir_embedded)]\n",
    "        rgbsigma = torch.cat(out_chunks, 0)\n",
    "\n",
    "    sigma = rgbsigma[:, -1].cpu().numpy()\n",
    "    sigma = np.maximum(sigma, 0)\n",
    "    sigma = sigma.reshape(N, N, 1)\n",
    "\n",
    "    # save to tiff slice\n",
    "    exp_path = root_dir\n",
    "    tifffile.imwrite(volume_output_file, sigma.astype('uint8'), append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "30bb980a990a251085a08b54e0ae26c6e312af495ec5c889c0335588031946be"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('nerf_pl': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
